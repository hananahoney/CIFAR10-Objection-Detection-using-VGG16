# -*- coding: utf-8 -*-
"""DL Project 3. CIFAR10 Objection Detection using VGG16 Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KbgYNXROvGkSgvlvXwbWZUYr6DT3Yblg

Importing CIFAR10 dataset from kaggle
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c cifar-10

from zipfile import ZipFile
dataset = '/content/cifar-10.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

!ls

!pip install py7zr

import py7zr

archive = py7zr.SevenZipFile('/content/train.7z', mode='r')
archive.extractall() # archive.extractall(path='path to folder in which you want to extract')
archive.close()

archive = py7zr.SevenZipFile('/content/test.7z', mode='r')
archive.extractall() # archive.extractall(path='path to folder in which you want to extract')
archive.close()

import os

filenames = os.listdir('/content/train')

print(filenames[:5])

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

labels_df = pd.read_csv('/content/trainLabels.csv')

labels_df.head(10)

labels_df.tail(10)

labels_df['label'].value_counts()

labels_dict={
    'airplane':0,
    'frog':1,
    'truck':2,
    'deer':3,
    'automobile':4,
    'bird':5,
    'horse':6,
    'ship':7,
    'cat':8,
    'dog':9,
}

labels = [labels_dict[i] for i in labels_df['label']]

print(labels)

import cv2
import matplotlib.pyplot as plt

img = cv2.imread('/content/train/5286.png')
plt.imshow(img)
plt.show()

img.shape

ids = labels_df['id']
print(ids)

data = []
for i in ids:
  img = cv2.imread('/content/train/'+str(i)+'.png')
  data.append(img)

len(data)

data

data[0].shape

X = np.array(data)
Y = np.array(labels)

print(X.shape)
print(Y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

X_train_std = X_train/255.0
X_test_std = X_test/255.0

"""**Applying ResNet50 Model**"""

import tensorflow as tf

model = tf.keras.applications.ResNet50(
    include_top=True,
    weights=None,
    input_tensor=None,
    input_shape=(32,32,3),
    pooling=True,
    classes=10,
    classifier_activation='softmax'
)

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train_std, y_train, epochs=10, validation_split=0.2)

"""As you can see simple resNet50 model is not performing well now we will use transfer learning technique in which we will take already trained weights of 'imagenet' dataset trained on resnet50 and on these weights we add some layers"""

from tensorflow import keras

resnet = keras.applications.ResNet50(
    include_top=False, #this will remove the output layer
    weights='imagenet',
    input_shape=(256,256,3),
    classes=10000,
    classifier_activation='softmax'
)

resnet.summary()

model = keras.models.Sequential()
model.add(keras.layers.UpSampling2D(size=(2,2)))
model.add(keras.layers.UpSampling2D(size=(2,2)))
model.add(keras.layers.UpSampling2D(size=(2,2)))
model.add(resnet)
model.add(keras.layers.Flatten())
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(64, activation='relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(32, activation='relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')

hist = model.fit(X_train, y_train, epochs=10, validation_split=0.2)

plt.plot(hist.history['loss'], label='train loss')
plt.plot(hist.history['val_loss'], lable='validation loss')
plt.show()

plt.plot(hist.history['accuracy'], label='train accuracy')
plt.plot(hist.history['val_accuracy'], lable='validation accuracy')
plt.show()

